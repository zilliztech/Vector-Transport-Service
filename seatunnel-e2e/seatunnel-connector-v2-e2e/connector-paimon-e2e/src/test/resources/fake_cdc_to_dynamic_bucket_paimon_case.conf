#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
######
###### This config file is a demonstration of streaming processing in seatunnel config
######

env {
  parallelism = 1
  job.mode = "BATCH"
}

source {
  FakeSource {
    schema = {
      columns = [
         {
            name = pk_id
            type = bigint
            nullable = false
            comment = "primary key id"
         },
         {
            name = name
            type = "string"
            nullable = true
            comment = "name"
         },
         {
            name = one_time
            type = timestamp
            nullable = false
            comment = "one time"
            columnScale = 0
         },
          {
             name = two_time
             type = timestamp
             nullable = false
             comment = "two time"
             columnScale = 3
          },
         {
            name = three_time
            type = timestamp
            nullable = false
            comment = "three time"
            columnScale = 6
         },
          {
             name = four_time
             type = timestamp
             nullable = false
             comment = "four time"
             columnScale = 9
          }
      ]
      primaryKey {
        name = "pk_id"
        columnNames = [pk_id]
      }
    }
    rows = [
      {
        kind = INSERT
        fields = [1, "A", "2024-03-10T10:00:12", "2024-03-10T10:00:00.123", "2024-03-10T10:00:00.123456", "2024-03-10T10:00:00.123456789"]
      },
      {
        kind = INSERT
        fields = [2, "B", "2024-03-10T10:00:12", "2024-03-10T10:00:00.123", "2024-03-10T10:00:00.123456", "2024-03-10T10:00:00.123456789"]
      },
      {
        kind = INSERT
        fields = [3, "C", "2024-03-10T10:00:12", "2024-03-10T10:00:00.123", "2024-03-10T10:00:00.123456", "2024-03-10T10:00:00.123456789"]
      },
      {
        kind = INSERT
        fields = [3, "C", "2024-03-10T10:00:12", "2024-03-10T10:00:00.123", "2024-03-10T10:00:00.123456", "2024-03-10T10:00:00.123456789"]
      },
      {
        kind = INSERT
        fields = [3, "C", "2024-03-10T10:00:12", "2024-03-10T10:00:00.123", "2024-03-10T10:00:00.123456", "2024-03-10T10:00:00.123456789"]
      },
      {
        kind = INSERT
        fields = [3, "C", "2024-03-10T10:00:12", "2024-03-10T10:00:00.123", "2024-03-10T10:00:00.123456", "2024-03-10T10:00:00.123456789"]
      },
      {
        kind = UPDATE_BEFORE
        fields = [1, "A", "2024-03-10T10:00:12", "2024-03-10T10:00:00.123", "2024-03-10T10:00:00.123456", "2024-03-10T10:00:00.123456789"]
      },
      {
        kind = UPDATE_AFTER
        fields = [1, "A_1", "2024-03-10T10:00:12", "2024-03-10T10:00:00.123", "2024-03-10T10:00:00.123456", "2024-03-10T10:00:00.123456789"]
      },
      {
        kind = DELETE
        fields = [2, "B", "2024-03-10T10:00:12", "2024-03-10T10:00:00.123", "2024-03-10T10:00:00.123456", "2024-03-10T10:00:00.123456789"]
      }
    ]
  }
}

transform {

}

sink {
  Paimon {
    warehouse = "file:///tmp/paimon"
    database = "default"
    table = "st_test_3"
    paimon.table.write-props = {
       bucket = -1
       dynamic-bucket.target-row-num = 50000
    }
  }
}
